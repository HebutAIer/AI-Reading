# Introduction

* **AI Problem**
    > * In the early days of artificial intelligence: Problem that can be described by a list of formal, mathenatical rules. 
    > * The true challenge to artificial intellignece: Problem that easy for people to perform but hard for people to describe formally.
* **Knowledge base**: seek to hard-code knowledge about the world in formal languages
    > * None of these projects has led to a major success.
* **Machine learning**: enable computers to tackle problems involving knowledge of the read world and make decisions that appear subjective.
    > * The performance of these simple machine learning algorithms depends heavily on the representation of the data.
    > * Model can learn how each of sample's features correlates with its labels, but cannot influence how features are defined in any way
* **Representation learning**: use machine learning to discover not only the mapping from representation to output but also the representation itself. 
    > * Result in much better performance that can be obtained with hand-designed minimal human intervention.
    > * Enable AI systems to rapidly adapt to new tasks, with minimal human intervention.
* **Deep learning**: allowing computers to learn from experience and understand the world in terms of a hierarchy of concepts, with each concept defined through its relation to simpler concepts. 

## 1.1 Who Should Read This Book
## 1.2 Historical Trends in Deep Learning
### 1.2.1 The Many Names and Changing Fortunes of Neural Networks
1. Cybernetics (1940-1960):
>1. The development of theories of biological learning.
>2. Implementations of the first models such as the perceptron, enabling the training of a single neuron.
>3. Cannot learn the XOR function led to a decline in the polularity of nn
2. Connectionism (1980-1990):
>1. Train a neural network with one or two hidden layers by back-propagation.
>2. The centeral idea in connectionism is that a large number of simple computational units can achieve intelligent behavior when networked together.
>3. Distributed representation: each input to a system should be represented by many features, and each feature should be involved in the representation.????
>4. AI research did not fulfill these unreasonable expectations, and other fields of machine learning made advances led to a decline in the popularity of nn.
3. Deep learning (2006-):
>1. Neuroscience has given us a reason to hope that a single deep learning algorithm can solve many different tasks. (Much of the mammalian brain might use a single algorithm to solve most of the different tasks that the brain solves.)
### 1.2.2 Increasing Dataset Sizes
1. The amount of skill required reduces as the amount of training data increases.
2. A rough rule of thumb is that a supervised deep learning algorithm: 
>1. will generally achieve acceptable performance with around 5000 labeled examples per category.
>2. will match or exceed human performance when trained with a dataset containing at least 10 millon labeled esamples
### 1.2.3 Increasing Model Sizes
1. Unless new technologies enable faster scaling, artificial neural networks will not have the same number of neurons as the human brain until at least the 2050s.
### New Word
1. desire 
2. conveive
3. routine
4. labor
5. tackle 
6. intuitive
7. sterile
8. circumscribe
9. wieldy
10. staff
11. vocal
12. viable
13. rebrand
14. flaw
15. waxed and waned
